{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7397a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LeakyReLU, ELU, BatchNormalization\n",
    "from keras import backend\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36dd9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"betterSimulation2.csv\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82827f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[\"sigma\"]\n",
    "X = data.drop(columns=[\"sigma\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88e53636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a85b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e156459",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200, input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(200))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dense(200))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73454add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 200)               1200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 200)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " elu_4 (ELU)                 (None, 200)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,201\n",
      "Trainable params: 42,401\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86562a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macongcong/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n",
      "2023-03-26 15:25:12.802283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 4s 13ms/step - loss: 0.1981 - val_loss: 0.1738\n",
      "Epoch 2/200\n",
      "  1/238 [..............................] - ETA: 2s - loss: 0.1411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 15:25:15.929873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1376 - val_loss: 0.1444\n",
      "Epoch 3/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1336 - val_loss: 0.1343\n",
      "Epoch 4/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1299 - val_loss: 0.1515\n",
      "Epoch 5/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1288 - val_loss: 0.1338\n",
      "Epoch 6/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1240 - val_loss: 0.1477\n",
      "Epoch 7/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1208 - val_loss: 0.1131\n",
      "Epoch 8/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1231 - val_loss: 0.1292\n",
      "Epoch 9/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1201 - val_loss: 0.1358\n",
      "Epoch 10/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1177 - val_loss: 0.1134\n",
      "Epoch 11/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1166 - val_loss: 0.1152\n",
      "Epoch 12/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1139 - val_loss: 0.1315\n",
      "Epoch 13/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1159 - val_loss: 0.1131\n",
      "Epoch 14/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1140 - val_loss: 0.1444\n",
      "Epoch 15/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1136 - val_loss: 0.1032\n",
      "Epoch 16/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1126 - val_loss: 0.1216\n",
      "Epoch 17/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1160 - val_loss: 0.1193\n",
      "Epoch 18/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1136 - val_loss: 0.1241\n",
      "Epoch 19/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1107 - val_loss: 0.1070\n",
      "Epoch 20/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1123 - val_loss: 0.1279\n",
      "Epoch 21/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1117 - val_loss: 0.1376\n",
      "Epoch 22/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1113 - val_loss: 0.1101\n",
      "Epoch 23/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.1094 - val_loss: 0.1065\n",
      "Epoch 24/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1098 - val_loss: 0.1276\n",
      "Epoch 25/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1082 - val_loss: 0.1026\n",
      "Epoch 26/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1081 - val_loss: 0.1308\n",
      "Epoch 27/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1110 - val_loss: 0.1097\n",
      "Epoch 28/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1110 - val_loss: 0.1144\n",
      "Epoch 29/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1056 - val_loss: 0.0978\n",
      "Epoch 30/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1071 - val_loss: 0.1130\n",
      "Epoch 31/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1069 - val_loss: 0.1006\n",
      "Epoch 32/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1095 - val_loss: 0.1075\n",
      "Epoch 33/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1073 - val_loss: 0.1014\n",
      "Epoch 34/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1057 - val_loss: 0.1162\n",
      "Epoch 35/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1067 - val_loss: 0.1121\n",
      "Epoch 36/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1074 - val_loss: 0.0970\n",
      "Epoch 37/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1056 - val_loss: 0.0992\n",
      "Epoch 38/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1063 - val_loss: 0.1013\n",
      "Epoch 39/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1055 - val_loss: 0.1008\n",
      "Epoch 40/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1055 - val_loss: 0.1149\n",
      "Epoch 41/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1052 - val_loss: 0.1039\n",
      "Epoch 42/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1049 - val_loss: 0.1060\n",
      "Epoch 43/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1024 - val_loss: 0.1005\n",
      "Epoch 44/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1027 - val_loss: 0.1189\n",
      "Epoch 45/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1042 - val_loss: 0.1028\n",
      "Epoch 46/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1027 - val_loss: 0.0941\n",
      "Epoch 47/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1022 - val_loss: 0.1003\n",
      "Epoch 48/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1000 - val_loss: 0.0951\n",
      "Epoch 49/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1027 - val_loss: 0.0951\n",
      "Epoch 50/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1023 - val_loss: 0.1151\n",
      "Epoch 51/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0993 - val_loss: 0.1110\n",
      "Epoch 52/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1013 - val_loss: 0.1038\n",
      "Epoch 53/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1009 - val_loss: 0.1065\n",
      "Epoch 54/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0990 - val_loss: 0.0966\n",
      "Epoch 55/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0995 - val_loss: 0.1050\n",
      "Epoch 56/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0989 - val_loss: 0.1013\n",
      "Epoch 57/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.1000 - val_loss: 0.1046\n",
      "Epoch 58/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0974 - val_loss: 0.1104\n",
      "Epoch 59/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0990 - val_loss: 0.1176\n",
      "Epoch 60/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0996 - val_loss: 0.1002\n",
      "Epoch 61/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0984 - val_loss: 0.1121\n",
      "Epoch 62/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0981 - val_loss: 0.0915\n",
      "Epoch 63/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0978 - val_loss: 0.1027\n",
      "Epoch 64/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0961 - val_loss: 0.0914\n",
      "Epoch 65/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0956 - val_loss: 0.0959\n",
      "Epoch 66/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0960 - val_loss: 0.1029\n",
      "Epoch 67/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0948 - val_loss: 0.1154\n",
      "Epoch 68/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0960 - val_loss: 0.0924\n",
      "Epoch 69/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0956 - val_loss: 0.1070\n",
      "Epoch 70/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0945 - val_loss: 0.0943\n",
      "Epoch 71/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0955 - val_loss: 0.0899\n",
      "Epoch 72/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0949 - val_loss: 0.0872\n",
      "Epoch 73/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0944 - val_loss: 0.1173\n",
      "Epoch 74/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0947 - val_loss: 0.1079\n",
      "Epoch 75/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0937 - val_loss: 0.0867\n",
      "Epoch 76/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0919 - val_loss: 0.1002\n",
      "Epoch 77/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0932 - val_loss: 0.0923\n",
      "Epoch 78/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0924 - val_loss: 0.1229\n",
      "Epoch 79/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0921 - val_loss: 0.0923\n",
      "Epoch 80/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0919 - val_loss: 0.0936\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0898\n",
      "Epoch 82/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0923 - val_loss: 0.0911\n",
      "Epoch 83/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0915 - val_loss: 0.0867\n",
      "Epoch 84/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0907 - val_loss: 0.1257\n",
      "Epoch 85/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0911 - val_loss: 0.0815\n",
      "Epoch 86/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0904 - val_loss: 0.0981\n",
      "Epoch 87/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0914 - val_loss: 0.1062\n",
      "Epoch 88/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0901 - val_loss: 0.0917\n",
      "Epoch 89/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0903 - val_loss: 0.0947\n",
      "Epoch 90/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0889 - val_loss: 0.0824\n",
      "Epoch 91/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0895 - val_loss: 0.0948\n",
      "Epoch 92/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0891 - val_loss: 0.0834\n",
      "Epoch 93/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0882 - val_loss: 0.0913\n",
      "Epoch 94/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0884 - val_loss: 0.0924\n",
      "Epoch 95/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0864 - val_loss: 0.0904\n",
      "Epoch 96/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0872 - val_loss: 0.0896\n",
      "Epoch 97/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0884 - val_loss: 0.0996\n",
      "Epoch 98/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0870 - val_loss: 0.0926\n",
      "Epoch 99/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0871 - val_loss: 0.1052\n",
      "Epoch 100/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0874 - val_loss: 0.0894\n",
      "Epoch 101/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0876 - val_loss: 0.0889\n",
      "Epoch 102/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0857 - val_loss: 0.0892\n",
      "Epoch 103/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0870 - val_loss: 0.1047\n",
      "Epoch 104/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0857 - val_loss: 0.1040\n",
      "Epoch 105/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0871 - val_loss: 0.0850\n",
      "Epoch 106/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0834 - val_loss: 0.0821\n",
      "Epoch 107/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0837 - val_loss: 0.0812\n",
      "Epoch 108/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0842 - val_loss: 0.1032\n",
      "Epoch 109/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0833 - val_loss: 0.0839\n",
      "Epoch 110/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0847 - val_loss: 0.0833\n",
      "Epoch 111/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0834 - val_loss: 0.0876\n",
      "Epoch 112/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0833 - val_loss: 0.0946\n",
      "Epoch 113/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 114/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0845 - val_loss: 0.1192\n",
      "Epoch 115/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0843 - val_loss: 0.0779\n",
      "Epoch 116/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0824 - val_loss: 0.0878\n",
      "Epoch 117/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0828 - val_loss: 0.1131\n",
      "Epoch 118/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0816 - val_loss: 0.0911\n",
      "Epoch 119/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0838 - val_loss: 0.1100\n",
      "Epoch 120/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0834 - val_loss: 0.1062\n",
      "Epoch 121/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0829 - val_loss: 0.0997\n",
      "Epoch 122/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 123/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0824 - val_loss: 0.0863\n",
      "Epoch 124/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0818 - val_loss: 0.0794\n",
      "Epoch 125/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0816 - val_loss: 0.0809\n",
      "Epoch 126/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0818 - val_loss: 0.1140\n",
      "Epoch 127/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0823 - val_loss: 0.0940\n",
      "Epoch 128/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0805 - val_loss: 0.0933\n",
      "Epoch 129/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 130/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0817 - val_loss: 0.0865\n",
      "Epoch 131/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0808 - val_loss: 0.0788\n",
      "Epoch 132/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0809 - val_loss: 0.0965\n",
      "Epoch 133/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0805 - val_loss: 0.0826\n",
      "Epoch 134/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0819 - val_loss: 0.1202\n",
      "Epoch 135/200\n",
      "238/238 [==============================] - 3s 13ms/step - loss: 0.0814 - val_loss: 0.0808\n",
      "Epoch 136/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0794 - val_loss: 0.0993\n",
      "Epoch 137/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0805 - val_loss: 0.0900\n",
      "Epoch 138/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0798 - val_loss: 0.0923\n",
      "Epoch 139/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0803 - val_loss: 0.1107\n",
      "Epoch 140/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0808 - val_loss: 0.0952\n",
      "Epoch 141/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0789 - val_loss: 0.0771\n",
      "Epoch 142/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0795 - val_loss: 0.0784\n",
      "Epoch 143/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0797 - val_loss: 0.0839\n",
      "Epoch 144/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0801 - val_loss: 0.0752\n",
      "Epoch 145/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0792 - val_loss: 0.1022\n",
      "Epoch 146/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0819 - val_loss: 0.0830\n",
      "Epoch 147/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0796 - val_loss: 0.0994\n",
      "Epoch 148/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0803 - val_loss: 0.0850\n",
      "Epoch 149/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0799 - val_loss: 0.0846\n",
      "Epoch 150/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0798 - val_loss: 0.0990\n",
      "Epoch 151/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0785 - val_loss: 0.0942\n",
      "Epoch 152/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0795 - val_loss: 0.0909\n",
      "Epoch 153/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0793 - val_loss: 0.0837\n",
      "Epoch 154/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0776 - val_loss: 0.0757\n",
      "Epoch 155/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0778 - val_loss: 0.1048\n",
      "Epoch 156/200\n",
      "238/238 [==============================] - 3s 13ms/step - loss: 0.0782 - val_loss: 0.0790\n",
      "Epoch 157/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0782 - val_loss: 0.0837\n",
      "Epoch 158/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0788 - val_loss: 0.0795\n",
      "Epoch 159/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0782 - val_loss: 0.1032\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0776 - val_loss: 0.0956\n",
      "Epoch 161/200\n",
      "238/238 [==============================] - 3s 13ms/step - loss: 0.0796 - val_loss: 0.0799\n",
      "Epoch 162/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0782 - val_loss: 0.1080\n",
      "Epoch 163/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0785 - val_loss: 0.0873\n",
      "Epoch 164/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0762 - val_loss: 0.0814\n",
      "Epoch 165/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0779 - val_loss: 0.0762\n",
      "Epoch 166/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0755 - val_loss: 0.1058\n",
      "Epoch 167/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0778 - val_loss: 0.0844\n",
      "Epoch 168/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0760 - val_loss: 0.0961\n",
      "Epoch 169/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0788 - val_loss: 0.0785\n",
      "Epoch 170/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0781 - val_loss: 0.0731\n",
      "Epoch 171/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0760 - val_loss: 0.0877\n",
      "Epoch 172/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0769 - val_loss: 0.1010\n",
      "Epoch 173/200\n",
      "238/238 [==============================] - 3s 11ms/step - loss: 0.0776 - val_loss: 0.0941\n",
      "Epoch 174/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0762 - val_loss: 0.1008\n",
      "Epoch 175/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0769 - val_loss: 0.0964\n",
      "Epoch 176/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0755 - val_loss: 0.0768\n",
      "Epoch 177/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0766 - val_loss: 0.0771\n",
      "Epoch 178/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0755 - val_loss: 0.0749\n",
      "Epoch 179/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0762 - val_loss: 0.0761\n",
      "Epoch 180/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0763 - val_loss: 0.1063\n",
      "Epoch 181/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0766 - val_loss: 0.0807\n",
      "Epoch 182/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0748 - val_loss: 0.0785\n",
      "Epoch 183/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0764 - val_loss: 0.1216\n",
      "Epoch 184/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0774 - val_loss: 0.0885\n",
      "Epoch 185/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0763 - val_loss: 0.0863\n",
      "Epoch 186/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0771 - val_loss: 0.1081\n",
      "Epoch 187/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0760 - val_loss: 0.0876\n",
      "Epoch 188/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0759 - val_loss: 0.0770\n",
      "Epoch 189/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0747 - val_loss: 0.0744\n",
      "Epoch 190/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0762 - val_loss: 0.0954\n",
      "Epoch 191/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0767 - val_loss: 0.0740\n",
      "Epoch 192/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0769 - val_loss: 0.0995\n",
      "Epoch 193/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0754 - val_loss: 0.0816\n",
      "Epoch 194/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0750 - val_loss: 0.0764\n",
      "Epoch 195/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0743 - val_loss: 0.0987\n",
      "Epoch 196/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0769 - val_loss: 0.0787\n",
      "Epoch 197/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0760 - val_loss: 0.1015\n",
      "Epoch 198/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0747 - val_loss: 0.0998\n",
      "Epoch 199/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0752 - val_loss: 0.0819\n",
      "Epoch 200/200\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0777 - val_loss: 0.0908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1024, epochs=200,\n",
    "                    validation_split = 0.1,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d9813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/938 [>.............................] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 15:34:33.331404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f10f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.575616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.861893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.446723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.191888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.202975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.594730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.350305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.207911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.635448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.251083\n",
       "1      0.575616\n",
       "2      0.861893\n",
       "3      0.446723\n",
       "4      0.191888\n",
       "...         ...\n",
       "29995  0.202975\n",
       "29996  0.594730\n",
       "29997  0.350305\n",
       "29998  0.207911\n",
       "29999  0.635448\n",
       "\n",
       "[30000 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22428d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/arraylike.py:110\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6258\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m-> 6259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/base.py:1327\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/series.py:3223\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   3219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (res1, res2)\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;66;03m# We do not pass dtype to ensure that the Series constructor\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;66;03m#  does inference in the case where `result` has object-dtype.\u001b[39;00m\n\u001b[0;32m-> 3223\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3224\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/construction.py:647\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    644\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[1;32m    645\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 647\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_silicon/lib/python3.9/site-packages/pandas/core/construction.py:698\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# i.e. PandasDtype(\"O\")\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.mean(np.abs(y_test - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69ea1dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67676768, 0.57373737, 0.85707071, ..., 0.42777778, 0.47929293,\n",
       "       0.32474747])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8501636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09027865260084621"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(y_test.values - y_pred.reshape(y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d6fb70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>r</th>\n",
       "      <th>call_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>429.369369</td>\n",
       "      <td>90.496037</td>\n",
       "      <td>0.584557</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>3.397743e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51775</th>\n",
       "      <td>217.967968</td>\n",
       "      <td>335.488643</td>\n",
       "      <td>2.369123</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>4.909617e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115253</th>\n",
       "      <td>401.411411</td>\n",
       "      <td>334.361935</td>\n",
       "      <td>1.177465</td>\n",
       "      <td>0.029596</td>\n",
       "      <td>1.722013e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299321</th>\n",
       "      <td>266.036036</td>\n",
       "      <td>136.840740</td>\n",
       "      <td>2.894854</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>1.481076e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173570</th>\n",
       "      <td>406.806807</td>\n",
       "      <td>146.447501</td>\n",
       "      <td>0.727673</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>2.633649e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199500</th>\n",
       "      <td>244.944945</td>\n",
       "      <td>104.499591</td>\n",
       "      <td>0.876630</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.413574e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244038</th>\n",
       "      <td>78.178178</td>\n",
       "      <td>501.743813</td>\n",
       "      <td>1.387758</td>\n",
       "      <td>0.023535</td>\n",
       "      <td>1.360923e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79446</th>\n",
       "      <td>62.482482</td>\n",
       "      <td>50.777940</td>\n",
       "      <td>0.161051</td>\n",
       "      <td>0.018889</td>\n",
       "      <td>1.237094e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276390</th>\n",
       "      <td>265.055055</td>\n",
       "      <td>53.484341</td>\n",
       "      <td>1.688593</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>2.137637e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144864</th>\n",
       "      <td>55.125125</td>\n",
       "      <td>264.416743</td>\n",
       "      <td>0.561191</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>3.746512e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 S           K         T         r    call_price\n",
       "4941    429.369369   90.496037  0.584557  0.016465  3.397743e+02\n",
       "51775   217.967968  335.488643  2.369123  0.023131  4.909617e+01\n",
       "115253  401.411411  334.361935  1.177465  0.029596  1.722013e+02\n",
       "299321  266.036036  136.840740  2.894854  0.011414  1.481076e+02\n",
       "173570  406.806807  146.447501  0.727673  0.028384  2.633649e+02\n",
       "...            ...         ...       ...       ...           ...\n",
       "199500  244.944945  104.499591  0.876630  0.010000  1.413574e+02\n",
       "244038   78.178178  501.743813  1.387758  0.023535  1.360923e-02\n",
       "79446    62.482482   50.777940  0.161051  0.018889  1.237094e+01\n",
       "276390  265.055055   53.484341  1.688593  0.023737  2.137637e+02\n",
       "144864   55.125125  264.416743  0.561191  0.026566  3.746512e-10\n",
       "\n",
       "[30000 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58d0c619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42568514, 0.00187833, 0.00482199, ..., 0.07747288, 0.27138236,\n",
       "       0.31070021])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_test.values - y_pred.reshape(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca5500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
